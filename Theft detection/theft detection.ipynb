{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c23a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551be9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and predict\n",
    "model_path = \"model.h5\"\n",
    "print(\"Loading model...\")\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccddc24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        \n",
    "        # Removing fc8 for feature extraction\n",
    "        # self.fc8 = nn.Linear(4096, 487)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.conv1(x))\n",
    "        h = self.pool1(h)\n",
    "        h = self.relu(self.conv2(h))\n",
    "        h = self.pool2(h)\n",
    "        h = self.relu(self.conv3a(h))\n",
    "        h = self.relu(self.conv3b(h))\n",
    "        h = self.pool3(h)\n",
    "        h = self.relu(self.conv4a(h))\n",
    "        h = self.relu(self.conv4b(h))\n",
    "        h = self.pool4(h)\n",
    "        h = self.relu(self.conv5a(h))\n",
    "        h = self.relu(self.conv5b(h))\n",
    "        h = self.pool5(h)\n",
    "\n",
    "        h = h.view(-1, 8192)  # Flattening before the fully connected layers\n",
    "        h = self.relu(self.fc6(h))\n",
    "        h = self.dropout(h)\n",
    "        h = self.relu(self.fc7(h))\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        # Skip the softmax and fc8 layer for feature extraction\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc087c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4920\\2232645889.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weight_path)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained weights from the pickle file\n",
    "def load_pretrained_weights(model, weight_path):\n",
    "    # Load the pre-trained weights\n",
    "    state_dict = torch.load(weight_path)\n",
    "\n",
    "    # Filter out unnecessary keys\n",
    "    filtered_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict()}\n",
    "\n",
    "    # Load the filtered state_dict into the model\n",
    "    model.load_state_dict(filtered_state_dict)\n",
    "# Video preprocessing\n",
    "def preprocess_video(video_path, clip_len=16):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (112, 112))  # Resize to 112x112 as required by C3D\n",
    "        frame = frame.astype(np.float32)\n",
    "        frame = (frame - np.mean(frame)) / np.std(frame)  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Convert to numpy array and group into clips of `clip_len` frames\n",
    "    frames = np.array(frames)\n",
    "    clips = []\n",
    "    for i in range(0, len(frames) - clip_len, clip_len):\n",
    "        clip = frames[i:i+clip_len]\n",
    "        clips.append(clip)\n",
    "    \n",
    "    # Convert clips to the required shape (Batch, Channels, Depth, Height, Width)\n",
    "    clips = np.array(clips)\n",
    "    clips = np.transpose(clips, (0, 4, 1, 2, 3))  # (Batch, C, D, H, W)\n",
    "    \n",
    "    return clips\n",
    "\n",
    "# Feature extraction\n",
    "def extract_c3d_features(video_path, model):\n",
    "    clips = preprocess_video(video_path)\n",
    "    features = []\n",
    "\n",
    "    for clip in clips:\n",
    "        clip_tensor = torch.tensor(clip, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "        with torch.no_grad():\n",
    "            output = model(clip_tensor)\n",
    "            features.append(output.squeeze().numpy())  # Extract the features\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Initialize the model and load weights\n",
    "model = C3D()\n",
    "load_pretrained_weights(model, 'c3d.pickle')  # Path to c3d.pickle\n",
    "\n",
    "# Example usage\n",
    "video_path = 'Proj Data/input/sample2.mp4'  # Path to your video file\n",
    "c3d_features = extract_c3d_features(video_path, model)\n",
    "# Extract the base name of the video without extension\n",
    "FeaturePath = video_path.replace('.mp4', '.txt')\n",
    "\n",
    "# Save the C3D features to the .txt file\n",
    "np.savetxt(FeaturePath, c3d_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8592ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4920\\3354235843.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('c3d.pickle')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize the model\n",
    "model = C3D()\n",
    "\n",
    "# Load the pre-trained weights\n",
    "state_dict = torch.load('c3d.pickle')\n",
    "\n",
    "# Filter out unnecessary keys\n",
    "filtered_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict()}\n",
    "\n",
    "# Load the filtered state_dict into the model\n",
    "model.load_state_dict(filtered_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ba028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive plotting in Jupyter\n",
    "#%matplotlib notebook\n",
    "\n",
    "# Seed initialization\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Helper functions to load model and weights\n",
    "def load_model(model_path):\n",
    "    model = load_model(model_path)\n",
    "    print(\"LOAD MODEL\")\n",
    "    return model\n",
    "\n",
    "def load_weights(model, weight_path):\n",
    "    dict2 = loadmat(weight_path)\n",
    "    dict = conv_dict(dict2)\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        weights = dict[str(i)]\n",
    "        layer.set_weights(weights)\n",
    "    return model\n",
    "\n",
    "def conv_dict(dict2):\n",
    "    dict = {}\n",
    "    for i in range(len(dict2)):\n",
    "        if str(i) in dict2:\n",
    "            weights = dict2[str(i)][0]\n",
    "            weights2 = [weight[0] if weight.shape == (1, x) else weight for weight, x in enumerate(weights)]\n",
    "            dict[str(i)] = weights2\n",
    "    return dict\n",
    "\n",
    "# Savitzky-Golay filter function\n",
    "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "    window_size = np.abs(np.int(window_size))\n",
    "    order = np.abs(np.int(order))\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"Window size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"Window size is too small for the polynomial order\")\n",
    "    \n",
    "    order_range = range(order + 1)\n",
    "    half_window = (window_size - 1) // 2\n",
    "    b = np.mat([[k ** i for i in order_range] for k in range(-half_window, half_window + 1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate ** deriv * factorial(deriv)\n",
    "    firstvals = y[0] - np.abs(y[1:half_window + 1][::-1] - y[0])\n",
    "    lastvals = y[-1] + np.abs(y[-half_window - 1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve(m[::-1], y, mode='valid')\n",
    "\n",
    "# Load video features\n",
    "def load_dataset_One_Video_Features(Test_Video_Path):\n",
    "    with open(Test_Video_Path, \"r\") as f:\n",
    "        words = f.read().split()\n",
    "    num_feat = len(words) // 4096\n",
    "    count = -1\n",
    "    VideoFeatues = []\n",
    "    for feat in range(0, int(num_feat)):\n",
    "        feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
    "        count += 1\n",
    "        VideoFeatues = np.vstack((VideoFeatues, feat_row1)) if count > 0 else feat_row1\n",
    "    return VideoFeatues\n",
    "\n",
    "# Visualization and video processing in Jupyter\n",
    "def display_predictions(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    Total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    total_segments = np.linspace(1, Total_frames, num=33).round()\n",
    "    \n",
    "    FeaturePath = video_path.replace('.mp4', '.txt')\n",
    "    inputs = load_dataset_One_Video_Features(FeaturePath)\n",
    "    \n",
    "    predictions = model.predict_on_batch(inputs)\n",
    "    Frames_Score = []\n",
    "    for iv in range(0, 32):\n",
    "        F_Score = np.tile(predictions[iv], (int(total_segments[iv+1]) - int(total_segments[iv]), 1)).flatten()\n",
    "        Frames_Score = np.hstack((Frames_Score, F_Score)) if iv > 0 else F_Score\n",
    "    \n",
    "    scores = savitzky_golay(Frames_Score, 101, 3)\n",
    "    x = np.linspace(1, Total_frames, Total_frames)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    i = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i % 25 == 0:\n",
    "            plt.plot(x[:i], scores[:i], color='r', linewidth=3)\n",
    "            plt.xlabel(\"Frame\")\n",
    "            plt.ylabel(\"Anomaly Score\")\n",
    "            plt.draw()\n",
    "            plt.pause(0.01)\n",
    "        i += 1\n",
    "    cap.release()\n",
    "\n",
    "# Load the model and predict\n",
    "\n",
    "model_path = \"model.h5\"  # Path in your local machine\n",
    "# weights_path = \"weights_L1L2.mat\"\n",
    "# video_path = \"Proj Data/input/sample2.mp4\"  # Replace with actual video file path\n",
    "# print(\"mAIN bEFORE\")\n",
    "# model = load_model(model_path)\n",
    "# load_weights(model, weights_path)\n",
    "# print(\"mAIN\")\n",
    "\n",
    "# # Display predictions for a video\n",
    "# display_predictions(video_path, model)\n",
    "try:\n",
    "    print(\"Loading model...\")\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded.\")\n",
    "    load_weights(model, weights_path)\n",
    "    print(\"Weights loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b5dc8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Function to create the model based on your JSON configuration\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Adding layers according to the JSON configuration\n",
    "    model.add(Dense(512, activation='relu', input_shape=(4096,), \n",
    "                    kernel_regularizer=l2(0.001), name='dense_1'))\n",
    "    model.add(Dropout(0.6, name='dropout_1'))\n",
    "    \n",
    "    model.add(Dense(32, activation='linear', name='dense_2', \n",
    "                    kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.6, name='dropout_2'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid', name='dense_3', \n",
    "                    kernel_regularizer=l2(0.001)))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_model()\n",
    "\n",
    "# Compile the model (you can specify your optimizer and loss function)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save('model.h5')\n",
    "\n",
    "print(\"Model saved as model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a41ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
